# Iterative Translation Assistant (Flask Edition)

## Description

The Iterative Translation Assistant is a web-based tool with a Python/Flask backend, designed to assist in translating sentences with the support of a Language Model (LLM). Instead of a single translation, the system presents four alternatives generated by the LLM, highlighting the differences between them on the client-side. The user can then edit any of the alternatives or accept the one that best suits their needs.

The core feature is iterative learning: each accepted translation is saved in the user's browser `localStorage`. These saved translations are then sent back to the server with the next translation request and used as few-shot examples in the prompt for the LLM. This aims to refine and contextualize the model's suggestions over time, adapting them to the user's style and preferences.

## Features

*   **Web Interface:** Frontend built with HTML, CSS, and JavaScript.
*   **Flask Backend:** Python/Flask server to handle translation requests.
*   **Sentence Input:** Field for the user to enter the original sentence.
*   **LLM Communication:**
    *   The Flask backend calls a `completion` function from an `LLM` class (provided in `llm.py`) to get translations.
    *   Requests 4 translation alternatives from the LLM.
*   **Difference Highlighting (Client-Side):** Differences between translation alternatives are visually highlighted in the browser using JavaScript.
*   **Direct Editing:** "Edit" button next to each alternative.
*   **Local Persistence (Client-Side):** Accepted translations (original-translated pair) are saved in the browser's `localStorage`.
*   **Continuous Prompt Improvement (Context via Client):** Saved translations from `localStorage` are sent to the backend with each new translation request. The backend uses them to build a contextualized prompt for the LLM.

## File Structure

*   `app.py`: Main Flask application, routes, and backend logic.
*   `llm.py`: **(Your existing file)** Contains the `LLM` class with the `completion` method.
*   `templates/`:
    *   `index.html`: Main HTML structure of the web page.
*   `static/`:
    *   `css/style.css`: Styles for the user interface.
    *   `js/script.js`: Client-side JavaScript logic (UI interaction, AJAX calls to backend, DOM manipulation).
    *   `js/utils.js`: JavaScript utility functions (e.g., difference highlighting, localStorage manipulation).
*   `requirements.txt`: Python dependencies (Flask, etc.).
*   `.gitignore`: To ignore unnecessary files in Git.
*   `README.md`: This file.

## How to Use

1.  **Prerequisites:**
    *   Python 3.x installed.
    *   An `llm.py` file in the project root with your `LLM` class and `completion` method.
        *   Expected structure in `llm.py`:
            ```python
            class LLM:
                def __init__(self, args_if_any):
                    # Initialize your model
                    pass

                def completion(self, prompt: str, num_alternatives: int = 1) -> list[str]:
                    """
                    Generates 'num_alternatives' completions for the given prompt.
                    Returns a list of strings.
                    """
                    # Your logic to call the LLM and get 'num_alternatives'
                    # Example mock:
                    # alternatives = []
                    # for i in range(num_alternatives):
                    #    alternatives.append(f"Mock translation {i+1} of: {prompt.split(':')[-1].strip()}")
                    # return alternatives
                    raise NotImplementedError("Implement the completion method in your LLM class")
            ```

2.  **Setup:**
    *   Clone the repository.
    *   Create and activate a virtual environment:
        ```bash
        python -m venv venv
        source venv/bin/activate  # On Windows: venv\Scripts\activate
        ```
    *   Install dependencies:
        ```bash
        pip install -r requirements.txt
        ```
    *   Ensure your `llm.py` is correctly configured (API keys, model paths, etc.).

3.  **Run the Application:**
    ```bash
    flask run
    # Or python app.py (if __main__ is configured)
    ```
4.  Open your browser and navigate to `http://127.0.0.1:5000/`.
5.  Enter the sentence you want to translate.
6.  Saved translations from `localStorage` will be automatically sent with the request.
7.  Analyze the 4 alternatives and edit them as needed.

## Technologies

*   **Backend:** Python, Flask
*   **Frontend:** HTML, CSS, JavaScript (Vanilla JS)
*   **Frontend-Backend Communication:** AJAX (`fetch` API)
*   **LLM Interface:** Your `llm.py` file
*   **Context Storage:** Browser `localStorage`.
*   **Difference Highlighting:** JavaScript (can use a library like `diff-match-patch` or custom implementation).

## Potential Future Improvements

*   Support for multiple source/target languages.
*   Option to export/import saved translations from `localStorage`.
*   Configuration of LLM parameters (temperature, etc.) via the UI.
*   User authentication to save translations server-side (instead of `localStorage`).
*   Enhanced error handling.
